{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neural network accuracy:  0.8311688311688312\n",
      "k-nearest neighbors accuracy:  0.8051948051948052\n",
      "m case scenario classification:  1\n",
      "best case scenario classification:  1\n",
      "average case scenario classification:  1\n",
      "worst case scenario classification:  1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# flag to find optimal parameters for neural network\n",
    "# keep false due to parameter checking taking 1 hour+\n",
    "find_optimal_nn = False\n",
    "\n",
    "# flag to find optimal k for k nearest neighbors algorithm\n",
    "# change to true to find optimal k for the k-nearest neighbors alg.\n",
    "find_optimal_kn = False\n",
    "\n",
    "# read in pre-processed csv\n",
    "data = pd.read_csv('final_data.csv')\n",
    "\n",
    "# grab the 100 most recent months for average calculations\n",
    "cols = list(data.tail(100))\n",
    "\n",
    "# regularize data by subtracting means\n",
    "means = {}\n",
    "for col in cols:\n",
    "    if 'Temp' in col:\n",
    "        mean = data[col].mean()\n",
    "        means[col] = mean\n",
    "        data[col] = data[col] - mean\n",
    "\n",
    "# calculate ACE value mean\n",
    "mean = data['ACE'].mean()\n",
    "\n",
    "# label is 1 if ACE is greater than the average, else label is 0\n",
    "data['ACE'] = data['ACE'].apply(lambda x: 1 if x > mean else 0)\n",
    "\n",
    "# split the features and the labels into separate frames\n",
    "examples = data.drop(['ACE', 'dt', 'Hurricane_IDs'], axis=1)\n",
    "labels = data['ACE']\n",
    "\n",
    "# split data into training (90% of samples) and testing (10% of samples) groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(examples, labels, test_size=0.1, random_state=0)\n",
    "\n",
    "# code used to find the optimal parameters for the neural network\n",
    "# uses brute force to train and test with all combinations of passed in parameters\n",
    "# takes about an hour to run\n",
    "if find_optimal_nn:\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "    parameter_space = {\n",
    "        'hidden_layer_sizes': [(10,), (20,), (30,), (40,), (50,), (60,), (70,), (80,), (90,), (100,)],\n",
    "        'alpha': [5e-4, 5e-5],\n",
    "        'learning_rate': ['constant','adaptive'],\n",
    "        'random_state': [None, 1, 2, 3],\n",
    "        'learning_rate_init': [0.005, 0.0005]\n",
    "    }\n",
    "\n",
    "    mlp = MLPClassifier(max_iter=1000000)\n",
    "    clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, verbose=1, cv=2)\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    print('Best parameters found: ', clf.best_params_)\n",
    "    print('Best score: ', clf.best_score_)\n",
    "\n",
    "# code used to train and score a neural network with optimized parameters\n",
    "# results in 83.12% accuracy on the testing set\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "mlp = MLPClassifier()\n",
    "params = {'hidden_layer_sizes': (10,), 'learning_rate': 'constant', 'learning_rate_init': 0.001, 'random_state': 1, 'solver': 'lbfgs', 'max_iter': 1000000}\n",
    "mlp.set_params(**params)\n",
    "mlp.fit(X_train, y_train)\n",
    "print('neural network accuracy: ', mlp.score(X_test, y_test))\n",
    "\n",
    "# code used to find optimal k value for k-nearest neighbors\n",
    "if find_optimal_kn:\n",
    "    max_score = 0\n",
    "    optimal_k = 0\n",
    "    for n in range(1, 20):\n",
    "        neigh = KNeighborsClassifier(n_neighbors=n, weights='uniform', algorithm='brute')\n",
    "        neigh.fit(X_train, y_train)\n",
    "        score = neigh.score(X_test, y_test)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            optimal_k = n\n",
    "    print('optimal k: ', optimal_k)\n",
    "\n",
    "# code used to train and test k-nearest neighbors with optimal k value\n",
    "neigh = KNeighborsClassifier(n_neighbors=10, weights='uniform', algorithm='brute')\n",
    "neigh.fit(X_train, y_train)\n",
    "print('k-nearest neighbors accuracy: ', neigh.score(X_test, y_test))\n",
    "\n",
    "# following code is used to craft future monthly vectors based on global warming trends\n",
    "# create a best case scenario feature vector\n",
    "low = means.copy()\n",
    "for k, v in low.items():\n",
    "    low[k] += 1.1\n",
    "low_vector = [\n",
    "    low['LandAverageTemperature'],\n",
    "    low['LandMinTemperature'],\n",
    "    low['LandMaxTemperature'],\n",
    "    low['LandAndOceanAverageTemperature'],\n",
    "    low['AvgTempUSA'],\n",
    "    low['AvgTempFlorida'],\n",
    "    low['AvgTempLouisiana'],\n",
    "    low['AvgTempNorthCarolina'],\n",
    "    low['AvgTempSouthCarolina'],\n",
    "    low['AvgTempTexas'],\n",
    "]\n",
    "\n",
    "# create an average case scenario feature vector\n",
    "med = means.copy()\n",
    "for k, v in med.items():\n",
    "    med[k] += 3.25\n",
    "med_vector = [\n",
    "    med['LandAverageTemperature'],\n",
    "    med['LandMinTemperature'],\n",
    "    med['LandMaxTemperature'],\n",
    "    med['LandAndOceanAverageTemperature'],\n",
    "    med['AvgTempUSA'],\n",
    "    med['AvgTempFlorida'],\n",
    "    med['AvgTempLouisiana'],\n",
    "    med['AvgTempNorthCarolina'],\n",
    "    med['AvgTempSouthCarolina'],\n",
    "    med['AvgTempTexas'],\n",
    "]\n",
    "\n",
    "# create a worst case scenario feature vector\n",
    "high = means.copy()\n",
    "for k, v in high.items():\n",
    "    high[k] += 5.4\n",
    "high_vector = [\n",
    "    high['LandAverageTemperature'],\n",
    "    high['LandMinTemperature'],\n",
    "    high['LandMaxTemperature'],\n",
    "    high['LandAndOceanAverageTemperature'],\n",
    "    high['AvgTempUSA'],\n",
    "    high['AvgTempFlorida'],\n",
    "    high['AvgTempLouisiana'],\n",
    "    high['AvgTempNorthCarolina'],\n",
    "    high['AvgTempSouthCarolina'],\n",
    "    high['AvgTempTexas'],\n",
    "]\n",
    "\n",
    "# uses our neural network to predict the severity of these future months\n",
    "# a prediction of 1 signifies above average hurricane severity\n",
    "print('best case scenario classification: ', mlp.predict([low_vector])[0])\n",
    "print('average case scenario classification: ', mlp.predict([med_vector])[0])\n",
    "print('worst case scenario classification: ', mlp.predict([high_vector])[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
